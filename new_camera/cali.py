import numpy as np
import cv2 as cv
import yaml
import time

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —à–∞—Ö–º–∞—Ç–Ω–æ–π –¥–æ—Å–∫–∏
CHESSBOARD_CORNER_NUM_X = 8
CHESSBOARD_CORNER_NUM_Y = 6
SQUARE_SIZE_MM = 25
CAMERA_PARAMETERS_OUTPUT_FILE = "cam2.yaml"
REQUIRED_FRAMES = 15

criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–æ—Å–∫–∏
objp = np.zeros((CHESSBOARD_CORNER_NUM_X * CHESSBOARD_CORNER_NUM_Y, 3), np.float32)
objp[:, :2] = np.mgrid[0:CHESSBOARD_CORNER_NUM_X, 0:CHESSBOARD_CORNER_NUM_Y].T.reshape(-1, 2)
objp *= SQUARE_SIZE_MM

objpoints = []
imgpoints = []

cap = cv.VideoCapture(0)
if not cap.isOpened():
    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É.")
    exit()

last_saved_time = 0
print(f"\nüì∑ –ù–∞–≤–µ–¥–∏ –∫–∞–º–µ—Ä—É –Ω–∞ —à–∞—Ö–º–∞—Ç–Ω—É—é –¥–æ—Å–∫—É. –ù—É–∂–Ω–æ {REQUIRED_FRAMES} —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤.")

while True:
    ret, frame = cap.read()
    if not ret:
        print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞.")
        break

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    found, corners = cv.findChessboardCorners(gray, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), None)

    if found:
        corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        cv.drawChessboardCorners(frame, (CHESSBOARD_CORNER_NUM_X, CHESSBOARD_CORNER_NUM_Y), corners2, found)

        # –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 1.5 —Å–µ–∫—É–Ω–¥—ã
        if time.time() - last_saved_time > 1.5:
            objpoints.append(objp)
            imgpoints.append(corners2)
            last_saved_time = time.time()
            print(f"‚úÖ –£–≥–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã ({len(objpoints)}/{REQUIRED_FRAMES})")

    # –ü—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞ —ç–∫—Ä–∞–Ω–µ
    cv.putText(frame, f"–°–Ω–∏–º–∫–æ–≤: {len(objpoints)}/{REQUIRED_FRAMES}", (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

    cv.imshow("–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã", frame)

    if cv.waitKey(1) & 0xFF == ord('q') or len(objpoints) >= REQUIRED_FRAMES:
        break

cap.release()
cv.destroyAllWindows()

# –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
print("\nüìê –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã...")
ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)

print("\nüìè –ú–∞—Ç—Ä–∏—Ü–∞ –∫–∞–º–µ—Ä—ã:\n", mtx)
print("\nüîÑ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–∏—Å—Ç–æ—Ä—Å–∏–∏:\n", dist)

mean_error = 0
for i in range(len(objpoints)):
    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)
    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2) / len(imgpoints2)
    mean_error += error

print(f"\n‚úÖ –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏: {mean_error / len(objpoints)}")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
data = {
    "camera_matrix": mtx.tolist(),
    "dist_coeff": dist.tolist(),
    "square_size_mm": SQUARE_SIZE_MM
}
with open(CAMERA_PARAMETERS_OUTPUT_FILE, "w") as f:
    yaml.dump(data, f)

print(f"\nüìÇ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {CAMERA_PARAMETERS_OUTPUT_FILE}")